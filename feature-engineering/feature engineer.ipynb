{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "import re\n",
    "import gensim\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "import nltk\n",
    "from colour import Color\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/tring/Desktop/SSENSE Project/eda/all_info.csv', sep = '|', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creation-date</th>\n",
       "      <th>sub-category</th>\n",
       "      <th>brand</th>\n",
       "      <th>name</th>\n",
       "      <th>sku</th>\n",
       "      <th>description</th>\n",
       "      <th>origin</th>\n",
       "      <th>composition</th>\n",
       "      <th>full-price</th>\n",
       "      <th>sale-price</th>\n",
       "      <th>discount-percent</th>\n",
       "      <th>remaining-sizes</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-18</td>\n",
       "      <td>beanies</td>\n",
       "      <td>The Elder Statesman</td>\n",
       "      <td>Black Short Bunny Echo Beanie</td>\n",
       "      <td>201014M138001</td>\n",
       "      <td>Rib knit cashmere beanie in black. Rolled brim...</td>\n",
       "      <td>United States</td>\n",
       "      <td>100% cashmere.</td>\n",
       "      <td>355</td>\n",
       "      <td>355</td>\n",
       "      <td>0</td>\n",
       "      <td>['UNI']</td>\n",
       "      <td>https://img.ssensemedia.com/images/201014M1380...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-12-18</td>\n",
       "      <td>beanies</td>\n",
       "      <td>PS by Paul Smith</td>\n",
       "      <td>Red Wool Zebra Beanie</td>\n",
       "      <td>201422M138012</td>\n",
       "      <td>Rib knit lambswool beanie in red. Signature gr...</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>100% lambswool.</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>['UNI']</td>\n",
       "      <td>https://img.ssensemedia.com/images/201422M1380...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-18</td>\n",
       "      <td>beanies</td>\n",
       "      <td>PS by Paul Smith</td>\n",
       "      <td>Black Wool Zebra Beanie</td>\n",
       "      <td>201422M138013</td>\n",
       "      <td>Rib knit lambswool beanie in navy. Signature g...</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>100% lambswool.</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>['UNI']</td>\n",
       "      <td>https://img.ssensemedia.com/images/201422M1380...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-18</td>\n",
       "      <td>iphone cases</td>\n",
       "      <td>Maison Margiela</td>\n",
       "      <td>Black Pouch iPhone Case</td>\n",
       "      <td>201168M170261</td>\n",
       "      <td>Grained leather shoulder bag-style iPhone case...</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Leather.</td>\n",
       "      <td>420</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>['UNI']</td>\n",
       "      <td>https://img.ssensemedia.com/images/201168M1702...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-18</td>\n",
       "      <td>necklaces</td>\n",
       "      <td>Maison Margiela</td>\n",
       "      <td>Silver Key Necklace</td>\n",
       "      <td>201168M145213</td>\n",
       "      <td>Curb chain necklace in sterling silver. Logo a...</td>\n",
       "      <td>Italy</td>\n",
       "      <td>925 sterling silver.</td>\n",
       "      <td>635</td>\n",
       "      <td>635</td>\n",
       "      <td>0</td>\n",
       "      <td>['UNI']</td>\n",
       "      <td>https://img.ssensemedia.com/images/201168M1452...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  creation-date  sub-category                brand  \\\n",
       "0    2019-12-18       beanies  The Elder Statesman   \n",
       "1    2019-12-18       beanies     PS by Paul Smith   \n",
       "2    2019-12-18       beanies     PS by Paul Smith   \n",
       "3    2019-12-18  iphone cases      Maison Margiela   \n",
       "4    2019-12-18     necklaces      Maison Margiela   \n",
       "\n",
       "                            name            sku  \\\n",
       "0  Black Short Bunny Echo Beanie  201014M138001   \n",
       "1          Red Wool Zebra Beanie  201422M138012   \n",
       "2        Black Wool Zebra Beanie  201422M138013   \n",
       "3        Black Pouch iPhone Case  201168M170261   \n",
       "4            Silver Key Necklace  201168M145213   \n",
       "\n",
       "                                         description          origin  \\\n",
       "0  Rib knit cashmere beanie in black. Rolled brim...   United States   \n",
       "1  Rib knit lambswool beanie in red. Signature gr...  United Kingdom   \n",
       "2  Rib knit lambswool beanie in navy. Signature g...  United Kingdom   \n",
       "3  Grained leather shoulder bag-style iPhone case...           Italy   \n",
       "4  Curb chain necklace in sterling silver. Logo a...           Italy   \n",
       "\n",
       "            composition  full-price  sale-price  discount-percent  \\\n",
       "0        100% cashmere.         355         355                 0   \n",
       "1       100% lambswool.         125         125                 0   \n",
       "2       100% lambswool.         125         125                 0   \n",
       "3              Leather.         420         420                 0   \n",
       "4  925 sterling silver.         635         635                 0   \n",
       "\n",
       "  remaining-sizes                                              image  \n",
       "0         ['UNI']  https://img.ssensemedia.com/images/201014M1380...  \n",
       "1         ['UNI']  https://img.ssensemedia.com/images/201422M1380...  \n",
       "2         ['UNI']  https://img.ssensemedia.com/images/201422M1380...  \n",
       "3         ['UNI']  https://img.ssensemedia.com/images/201168M1702...  \n",
       "4         ['UNI']  https://img.ssensemedia.com/images/201168M1452...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation date does not seem to be neccessary for the recommendation system. It is however, useful for other tasks like trend analysis. Therefore, for the sake of the model, we drop the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub-category</th>\n",
       "      <th>brand</th>\n",
       "      <th>name</th>\n",
       "      <th>sku</th>\n",
       "      <th>description</th>\n",
       "      <th>origin</th>\n",
       "      <th>composition</th>\n",
       "      <th>full-price</th>\n",
       "      <th>sale-price</th>\n",
       "      <th>discount-percent</th>\n",
       "      <th>remaining-sizes</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beanies</td>\n",
       "      <td>The Elder Statesman</td>\n",
       "      <td>Black Short Bunny Echo Beanie</td>\n",
       "      <td>201014M138001</td>\n",
       "      <td>Rib knit cashmere beanie in black. Rolled brim...</td>\n",
       "      <td>United States</td>\n",
       "      <td>100% cashmere.</td>\n",
       "      <td>355</td>\n",
       "      <td>355</td>\n",
       "      <td>0</td>\n",
       "      <td>['UNI']</td>\n",
       "      <td>https://img.ssensemedia.com/images/201014M1380...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beanies</td>\n",
       "      <td>PS by Paul Smith</td>\n",
       "      <td>Red Wool Zebra Beanie</td>\n",
       "      <td>201422M138012</td>\n",
       "      <td>Rib knit lambswool beanie in red. Signature gr...</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>100% lambswool.</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>['UNI']</td>\n",
       "      <td>https://img.ssensemedia.com/images/201422M1380...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beanies</td>\n",
       "      <td>PS by Paul Smith</td>\n",
       "      <td>Black Wool Zebra Beanie</td>\n",
       "      <td>201422M138013</td>\n",
       "      <td>Rib knit lambswool beanie in navy. Signature g...</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>100% lambswool.</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>['UNI']</td>\n",
       "      <td>https://img.ssensemedia.com/images/201422M1380...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iphone cases</td>\n",
       "      <td>Maison Margiela</td>\n",
       "      <td>Black Pouch iPhone Case</td>\n",
       "      <td>201168M170261</td>\n",
       "      <td>Grained leather shoulder bag-style iPhone case...</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Leather.</td>\n",
       "      <td>420</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>['UNI']</td>\n",
       "      <td>https://img.ssensemedia.com/images/201168M1702...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>necklaces</td>\n",
       "      <td>Maison Margiela</td>\n",
       "      <td>Silver Key Necklace</td>\n",
       "      <td>201168M145213</td>\n",
       "      <td>Curb chain necklace in sterling silver. Logo a...</td>\n",
       "      <td>Italy</td>\n",
       "      <td>925 sterling silver.</td>\n",
       "      <td>635</td>\n",
       "      <td>635</td>\n",
       "      <td>0</td>\n",
       "      <td>['UNI']</td>\n",
       "      <td>https://img.ssensemedia.com/images/201168M1452...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sub-category                brand                           name  \\\n",
       "0       beanies  The Elder Statesman  Black Short Bunny Echo Beanie   \n",
       "1       beanies     PS by Paul Smith          Red Wool Zebra Beanie   \n",
       "2       beanies     PS by Paul Smith        Black Wool Zebra Beanie   \n",
       "3  iphone cases      Maison Margiela        Black Pouch iPhone Case   \n",
       "4     necklaces      Maison Margiela            Silver Key Necklace   \n",
       "\n",
       "             sku                                        description  \\\n",
       "0  201014M138001  Rib knit cashmere beanie in black. Rolled brim...   \n",
       "1  201422M138012  Rib knit lambswool beanie in red. Signature gr...   \n",
       "2  201422M138013  Rib knit lambswool beanie in navy. Signature g...   \n",
       "3  201168M170261  Grained leather shoulder bag-style iPhone case...   \n",
       "4  201168M145213  Curb chain necklace in sterling silver. Logo a...   \n",
       "\n",
       "           origin           composition  full-price  sale-price  \\\n",
       "0   United States        100% cashmere.         355         355   \n",
       "1  United Kingdom       100% lambswool.         125         125   \n",
       "2  United Kingdom       100% lambswool.         125         125   \n",
       "3           Italy              Leather.         420         420   \n",
       "4           Italy  925 sterling silver.         635         635   \n",
       "\n",
       "   discount-percent remaining-sizes  \\\n",
       "0                 0         ['UNI']   \n",
       "1                 0         ['UNI']   \n",
       "2                 0         ['UNI']   \n",
       "3                 0         ['UNI']   \n",
       "4                 0         ['UNI']   \n",
       "\n",
       "                                               image  \n",
       "0  https://img.ssensemedia.com/images/201014M1380...  \n",
       "1  https://img.ssensemedia.com/images/201422M1380...  \n",
       "2  https://img.ssensemedia.com/images/201422M1380...  \n",
       "3  https://img.ssensemedia.com/images/201168M1702...  \n",
       "4  https://img.ssensemedia.com/images/201168M1452...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns = ['creation-date'], axis = 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       accessories  backpacks  bags  bars  beanies  belts  biker  blankets  \\\n",
      "0                0          0     0     0        1      0      0         0   \n",
      "1                0          0     0     0        1      0      0         0   \n",
      "2                0          0     0     0        1      0      0         0   \n",
      "3                0          0     0     0        0      0      0         0   \n",
      "4                0          0     0     0        0      0      0         0   \n",
      "...            ...        ...   ...   ...      ...    ...    ...       ...   \n",
      "28987            0          0     0     0        0      0      0         0   \n",
      "28988            0          0     0     0        0      0      0         0   \n",
      "28989            0          0     0     0        0      0      0         0   \n",
      "28990            0          0     0     0        0      0      0         0   \n",
      "28991            0          0     0     0        0      0      0         0   \n",
      "\n",
      "       blazers  boat  ...  up  ups  v  vests  waistcoats  wallets  watches  \\\n",
      "0            0     0  ...   0    0  0      0           0        0        0   \n",
      "1            0     0  ...   0    0  0      0           0        0        0   \n",
      "2            0     0  ...   0    0  0      0           0        0        0   \n",
      "3            0     0  ...   0    0  0      0           0        0        0   \n",
      "4            0     0  ...   0    0  0      0           0        0        0   \n",
      "...        ...   ...  ...  ..  ... ..    ...         ...      ...      ...   \n",
      "28987        0     0  ...   0    0  0      0           0        0        0   \n",
      "28988        0     0  ...   0    0  0      0           0        0        0   \n",
      "28989        0     0  ...   0    0  0      0           0        0        0   \n",
      "28990        0     0  ...   0    0  0      0           0        0        0   \n",
      "28991        0     0  ...   0    1  0      0           0        0        0   \n",
      "\n",
      "       wingtip  zip  zipups  \n",
      "0            0    0       0  \n",
      "1            0    0       0  \n",
      "2            0    0       0  \n",
      "3            0    0       0  \n",
      "4            0    0       0  \n",
      "...        ...  ...     ...  \n",
      "28987        0    0       0  \n",
      "28988        0    0       0  \n",
      "28989        0    0       0  \n",
      "28990        0    0       0  \n",
      "28991        0    0       0  \n",
      "\n",
      "[28992 rows x 116 columns]\n"
     ]
    }
   ],
   "source": [
    "category_mlb = MultiLabelBinarizer()\n",
    "\n",
    "category_matrix = pd.DataFrame(category_mlb.fit_transform(data['sub-category'].str.split(' ')),columns=category_mlb.classes_, index=data.index)\n",
    "\n",
    "print(category_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brands seem be unique to their own, however, there are certain collaborations, collections from the same designers seperated into different brands. We will convert them to the designers name manually as there are not that many cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['The Elder Statesman', 'PS by Paul Smith', 'Maison Margiela',\n",
       "       'Fendi', 'Carhartt Work In Progress', 'AMI Alexandre Mattiussi',\n",
       "       'R13', 'Alexander McQueen', 'Alan Crocetti', 'Paul Smith',\n",
       "       'Raf Simons', 'Loewe', 'Ermenegildo Zegna', 'adidas Originals',\n",
       "       'adidas Originals by Alexander Wang', 'Noah NYC', 'Saint Laurent',\n",
       "       'Burberry', 'Dolce & Gabbana', 'Carne Bollente', 'Frenckenberger',\n",
       "       'Givenchy', 'Vivienne Westwood', 'Balenciaga', 'Kuboraum', 'Dita',\n",
       "       'Ray-Ban', 'Etro', 'Marni', 'Valentino', 'Juun.J',\n",
       "       'Giorgio Armani', 'Eyevan 7285', 'Yuichi Toyama', 'Moschino',\n",
       "       'Thom Browne', 'Tiger of Sweden', 'Norse Projects',\n",
       "       'Saturdays NYC', 'A.P.C.', 'Gucci', 'Christian Louboutin',\n",
       "       'Reebok by Pyer Moss', 'Stone Island', '1017 ALYX 9SM', 'Y-3',\n",
       "       'Matsuda', 'Mykita', 'Bottega Veneta', 'Ralph Lauren Purple Label',\n",
       "       'Prada', 'Moncler Genius', 'Versace', 'Heron Preston', '032c',\n",
       "       'Marine Serre', 'McQ Alexander McQueen', 'Off-White', 'Le Gramme',\n",
       "       'Palm Angels', 'Jil Sander+', 'Jil Sander', 'Kenzo', 'Chin Teo',\n",
       "       'Thierry Lasry', 'Smythson', 'mastermind WORLD', 'Acne Studios',\n",
       "       'TAKAHIROMIYASHITA TheSoloist.', 'Aries', 'Salvatore Ferragamo',\n",
       "       'Stolen Girlfriends Club', 'Dsquared2', 'Tom Ford',\n",
       "       'Yohji Yamamoto', 'Officine Générale', 'Nike', 'Moncler',\n",
       "       'Landlord', 'Bleue Burnham', 'Oliver Peoples The Row',\n",
       "       'Mr. Leight', 'Linda Farrow Luxe', 'Oliver Peoples',\n",
       "       'Marcelo Burlon County of Milan', 'Daniel W. Fletcher',\n",
       "       'Double Rainbouu', 'Boss', 'Issey Miyake Men', 'C2H4', 'Hugo',\n",
       "       'Maison Kitsuné', 'A-Cold-Wall*', 'ADER error', 'Persol', 'Ambush',\n",
       "       '424', 'Cutler And Gross', 'Études', 'Tom Wood', 'Jacquemus',\n",
       "       'Amiri', 'Blue Blue Japan', 'Martine Ali', 'Opening Ceremony',\n",
       "       'Visvim', 'Aimé Leon Dore', 'Guidi', 'Fumito Ganryu',\n",
       "       '11 by Boris Bidjan Saberi', 'Comme des Garçons Homme Deux',\n",
       "       'Clot', 'JW Anderson', 'Neil Barrett', 'Emanuele Bicocchi',\n",
       "       'Affix', 'rag & bone', 'Rick Owens', 'Bao Bao Issey Miyake',\n",
       "       'Comme des Garçons Wallets', 'Satisfy', 'South2 West8',\n",
       "       'Coach 1941', 'Random Identities', 'Veilance', 'Kei Shigenaga',\n",
       "       'Mackage', 'Oakley by Samuel Ross', 'Rhude', 'Dior Homme',\n",
       "       'Master & Dynamic', \"Levi's\", 'paa', 'Han Kjobenhavn',\n",
       "       'Common Projects', 'Nasaseasons', 'RAEN', 'Nudie Jeans',\n",
       "       'Master-Piece Co', 'Cottweiler', 'Axel Arigato',\n",
       "       'Enfants Riches Déprimés', 'Ugo Cacciatori', 'N.Hoolywood',\n",
       "       'Fear of God', 'Gentle Monster', 'Robert Geller', 'Lemaire',\n",
       "       'Song for the Mute', 'Y/Project', 'VETEMENTS', 'Neighborhood',\n",
       "       'We11done', 'GmbH', 'Undercover', 'Ann Demeulemeester', 'Harmony',\n",
       "       'Giuseppe Zanotti', 'Polythene* Optics', 'Kiko Kostadinov',\n",
       "       'Sacai', 'Faith Connexion', 'Julius', 'Dries Van Noten', 'MISBHV',\n",
       "       'Martine Rose', 'Bless', \"D'heygere\", 'Paul Smith by Mark Mahoney',\n",
       "       'Comme des Garçons Homme', 'Polo Ralph Lauren', 'Martyre',\n",
       "       'Moncler Grenoble', 'Unravel', 'Isabel Benenato', 'Wacko Maria',\n",
       "       'Sasquatchfabrix.', 'Balmain', 'Nanamica', 'Botter', 'Phipps',\n",
       "       'Pearls Before Swine', 'Rick Owens Drkshdw', 'Sunspel', 'VIU',\n",
       "       'Noon Goons', 'Valextra', 'Jan-Jan Van Essche',\n",
       "       'Versace Underwear', 'Alexander Wang', 'Stay Made', 'Z Zegna',\n",
       "       'Pierre Hardy', 'Reese Cooper', 'ERL', 'Oberkampf', 'Spencer Badu',\n",
       "       'Doublet', 'Christian Dada', 'D.Gnak by Kang.D', 'MSGM',\n",
       "       'WWW.WILLSHOTT', 'Yang Li', 'paria /FARZANEH',\n",
       "       'Versace Jeans Couture', 'Alanui', 'Maximum Henry', 'Goodfight',\n",
       "       'The North Face', 'Perks and Mini', 'Needles', 'Minotaur', 'OAMC',\n",
       "       'Linder', 'Stella McCartney', 'RETROSUPERFUTURE', 'Xander Zhou',\n",
       "       'Afterhomework', 'BED J.W. FORD', 'Matthew Adams Dolan',\n",
       "       'The Viridi-anne', 'Comme des Garçons Homme Plus', 'nonnative',\n",
       "       'Lanvin', 'St-Henri', 'Second/Layer', 'Name.',\n",
       "       'Charles Jeffrey Loverboy', 'Johnlawrencesullivan',\n",
       "       'Engineered Garments', 'Martin Asbjorn', 'Isabel Marant',\n",
       "       'Judy Turner', 'Kozaburo', 'Eckhaus Latta', 'Missoni', 'Brioni',\n",
       "       'Tibi', 'Alain Mikli Paris', 'Feng Chen Wang', 'Toogood', 'NOR',\n",
       "       'Kassl Editions', 'Sulvam', 'Bode', 'All Blues',\n",
       "       'Marni Dance Bunny', 'Champion Reverse Weave', 'Garrett Leight',\n",
       "       'AGR', 'Haider Ackermann', 'Liam Hodges', 'Boris Bidjan Saberi',\n",
       "       'CMMN SWDN', 'Bunney', 'Roberi & Fraud', 'Native Sons',\n",
       "       'Abasi Rosborough', 'GR10K', 'Diesel Red Tag', 'Our Legacy',\n",
       "       'District Vision', 'Nahmias', 'Innerraum', 'Serapis',\n",
       "       'Band of Outsiders', 'Luka Sabbat x Monini', 'Deepti', '99% IS',\n",
       "       'lool', 'BLYSZAK', 'Belstaff', 'HOPE', 'Golden Goose',\n",
       "       'Homme Plissé Issey Miyake', 'Eastpak', 'Côte & Ciel', 'Diesel',\n",
       "       'Officine Creative', 'Heliot Emil', '3.1 Phillip Lim',\n",
       "       '132 5. ISSEY MIYAKE', 'Li-Ning', 'Sunnei', 'A. A. Spectrum',\n",
       "       'Comme des Garçons Shirt', 'NAPA by Martine Rose', 'Sankuanz',\n",
       "       'Wooyoungmi', 'Marsèll', 'Ribeyron', 'Camiel Fortgens',\n",
       "       'Canada Goose', 'Essentials', 'Solid & Striped',\n",
       "       'Tiger of Sweden Jeans', 'Frame', 'Rochambeau', 'The Very Warm',\n",
       "       'Craig Green', \"L'Homme Rouge\", 'S.R. STUDIO. LA. CA.', 'Converse',\n",
       "       'Stutterheim', 'Cobra S.C.', 'Barena', '49Winters', 'Sies Marjan',\n",
       "       'Ksubi', 'adidas x Missoni', \"Levi's Made & Crafted\", 'Pyer Moss',\n",
       "       'Comme des Garçons Play', 'Mowalola', 'Helmut Lang',\n",
       "       'Vyner Articles', \"Levi's Vintage Clothing\",\n",
       "       'Who Decides War by MRDR BRVDO', 'John Elliott',\n",
       "       'Naked & Famous Denim', 'Nobis', 'Calvin Klein Underwear',\n",
       "       'all in', 'Dickies Construct', 'Casablanca', 'Harris Wharf London',\n",
       "       'Kanuk', 'Bather', 'Schott', 'Vilebrequin', 'Lacoste',\n",
       "       'Reebok Classics', 'Hot Mess', 'Yves Salomon - Army', 'Herno',\n",
       "       'Descente Allterrain', 'Billy', 'Parajumpers', 'Nanushka', 'GCDS',\n",
       "       'Junya Watanabe', 'Everest Isles', 'Yves Salomon', 'Woolrich',\n",
       "       'SSS World Corp', 'Ottolinger', 'The North Face Black Series',\n",
       "       'Calvin Klein Jeans Est. 1978', 'Worstok', 'Moussy Vintage',\n",
       "       'Greg Lauren', 'Mr & Mrs Italy', 'Stone Island Shadow Project',\n",
       "       'Warren Lotas', 'Studio Nicholson', 'ALMOSTBLACK',\n",
       "       'Filling Pieces', 'Miharayasuhiro', 'NikeLab', 'Chen Peng',\n",
       "       'Hed Mayner', 'Namacheko', 'Wales Bonner', 'Palomo Spain',\n",
       "       'Mackintosh', \"Schnayderman's\", 'Eytys', 'Eidos', 'Stefan Cooke',\n",
       "       'Kuro', 'Joseph', 'Adaptation', 'Kanghyuk', 'Bianca Saunders',\n",
       "       'Post Archive Faction (PAF)', 'Deveaux New York', 'Resort Corps',\n",
       "       'Remi Relief', 'LQQK Studio for Paul & Shark', 'Telfar', 'Wonders',\n",
       "       'Keenkee', 'Onia', 'Vier', 'Ziggy Chen',\n",
       "       'Colmar A.G.E. by Shayne Oliver', 'Asics', 'Mugler', 'Blackmerle',\n",
       "       'Baja East', 'Anton Belinskiy', 'House of the Very Islands',\n",
       "       'D by D', 'Ahluwalia Studio', 'Simon Miller', 'Gosha Rubchinskiy',\n",
       "       'CHILDS', 'A_Plan_Application', 'Mackintosh 0004',\n",
       "       'Diet Butcher Slim Skin', 'Chin Mens', 'Jeanerica', 'Blondey',\n",
       "       'Kwaidan Editions', 'Calvin Klein 205W39NYC', 'Versus',\n",
       "       'Nomenklatura Studio', 'Éditions M.R', 'Facetasm', 'Lad Musician',\n",
       "       'Wheir Bobson', 'Stephan Schneider', 'Vans', 'B Sides', 'both',\n",
       "       'Dr. Martens', 'Suicoke', 'New Balance', 'Athletics Footwear',\n",
       "       'Toga Virilis', 'R.M. Williams',\n",
       "       'adidas Originals x Pharrell Williams', 'Salomon', 'Diemme', 'ROA',\n",
       "       'ION', 'Article No.', \"Church's\", 'Clarks Originals', 'Feit',\n",
       "       'Spalwart', 'ETQ Amsterdam', 'Castañer', 'Aprix', 'Malibu Sandals',\n",
       "       'Nike ACG', 'Hender Scheme', 'H by Hudson'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['brand'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['brand'] = data['brand'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.brand == 'adidas originals by alexander wang' ,'brand'] = 'adidas,alexander wang'\n",
    "data.loc[data.brand == 'adidas originals x pharrell williams' ,'brand'] = 'adidas' #PW does not have a private line on SSENSE\n",
    "data.loc[data.brand == 'adidas x missoni' ,'brand'] = 'adidas,missoni' #PW does not have a private line on SSENSE\n",
    "data.loc[(data.brand == '11 by boris bidjan saberi') & (data.name.str.contains('Salomon')) ,'brand'] = 'boris bidjan saberi,salomon'\n",
    "data.loc[(data.brand == '424') & (data.name.str.contains('adidas')),'brand'] = '424,adidas'\n",
    "data.loc[(data.brand == 'junya watanabe') & (data.name.str.contains('New Balance')) ,'brand'] = 'junya watanabe,new balance'\n",
    "data.loc[(data.brand == 'harmony') & (data.name.str.contains('Asics')) ,'brand'] = 'harmony,asics'\n",
    "data.loc[(data.brand == 'c2h4') & (data.name.str.contains('Asics')) ,'brand'] = 'c2h4,asics'\n",
    "data.loc[(data.brand == 'kiko kostadinov') & (data.name.str.contains('Asics')) ,'brand'] = 'kiko kostadinov,asics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_brand(df, old_brand, common_brand):\n",
    "    df.loc[df.brand.str.contains(old_brand), 'brand'] = common_brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_change = {'11 by boris bidjan saberi': 'boris bidjan saberi',\n",
    "             'adidas originals': 'adidas',\n",
    "             'issey miyake': 'issey miyake',\n",
    "             'boss': 'hugo boss',\n",
    "             'hugo': 'hugo boss',\n",
    "             'calvin klein': 'calvin klein',\n",
    "             'comme des garçons': 'comme des garçons',\n",
    "             'zegna': 'zegna',\n",
    "             'jil sander': 'jil sander',\n",
    "             'marni': 'marni',\n",
    "             'alexander mcqueen': 'alexander mcqueen',\n",
    "             'moncler': 'moncler',\n",
    "             'oliver peoples': 'oliver peoples',\n",
    "             'paul smith': 'paul smith',\n",
    "             'ralph lauren': 'ralph lauren',\n",
    "             'rick owens': 'rick owens',\n",
    "             'versace': 'versace',\n",
    "             'y-3': 'yohji yamamoto',\n",
    "             'diesel': 'diesel',\n",
    "             \"levi's\": \"levi's\",\n",
    "             'mackintosh': 'mackintosh',\n",
    "             'martine rose': 'martine rose',\n",
    "             'nike': 'nike',\n",
    "             'reebok': 'reebok',\n",
    "             'stone island': 'stone island',\n",
    "             'the north face': 'north face',\n",
    "             'tiger of sweden': 'tiger of sweden',\n",
    "             'yves salomon': 'yves salomon',\n",
    "             'b by d':'kang dong',\n",
    "             'd.gnak by kang.d': 'kang dong'\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for old_brand, common_brand in name_change.items():\n",
    "    change_brand(data, old_brand, common_brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['the elder statesman', 'paul smith', 'maison margiela', 'fendi',\n",
       "       'carhartt work in progress', 'ami alexandre mattiussi', 'r13',\n",
       "       'alexander mcqueen', 'alan crocetti', 'raf simons', 'loewe',\n",
       "       'zegna', 'adidas', 'adidas,alexander wang', 'noah nyc',\n",
       "       'saint laurent', 'burberry', 'dolce & gabbana', 'carne bollente',\n",
       "       'frenckenberger', 'givenchy', 'vivienne westwood', 'balenciaga',\n",
       "       'kuboraum', 'dita', 'ray-ban', 'etro', 'marni', 'valentino',\n",
       "       'juun.j', 'giorgio armani', 'eyevan 7285', 'yuichi toyama',\n",
       "       'moschino', 'thom browne', 'tiger of sweden', 'norse projects',\n",
       "       'saturdays nyc', 'a.p.c.', 'gucci', 'christian louboutin',\n",
       "       'reebok', 'stone island', '1017 alyx 9sm', 'yohji yamamoto',\n",
       "       'matsuda', 'mykita', 'bottega veneta', 'ralph lauren', 'prada',\n",
       "       'moncler', 'versace', 'heron preston', '032c', 'marine serre',\n",
       "       'off-white', 'le gramme', 'palm angels', 'jil sander', 'kenzo',\n",
       "       'chin teo', 'thierry lasry', 'smythson', 'mastermind world',\n",
       "       'acne studios', 'takahiromiyashita thesoloist.', 'aries',\n",
       "       'salvatore ferragamo', 'stolen girlfriends club', 'dsquared2',\n",
       "       'tom ford', 'officine générale', 'nike', 'landlord',\n",
       "       'bleue burnham', 'oliver peoples', 'mr. leight',\n",
       "       'linda farrow luxe', 'marcelo burlon county of milan',\n",
       "       'daniel w. fletcher', 'double rainbouu', 'hugo boss',\n",
       "       'issey miyake', 'c2h4', 'maison kitsuné', 'a-cold-wall*',\n",
       "       'ader error', 'persol', 'ambush', '424', 'cutler and gross',\n",
       "       'études', 'tom wood', 'jacquemus', 'amiri', 'blue blue japan',\n",
       "       'martine ali', 'opening ceremony', 'visvim', 'aimé leon dore',\n",
       "       'guidi', 'fumito ganryu', 'boris bidjan saberi',\n",
       "       'comme des garçons', 'clot', 'jw anderson', 'neil barrett',\n",
       "       'emanuele bicocchi', 'affix', 'rag & bone', 'rick owens',\n",
       "       'satisfy', 'south2 west8', 'coach 1941', 'random identities',\n",
       "       'veilance', 'kei shigenaga', 'mackage', 'oakley by samuel ross',\n",
       "       'rhude', 'dior homme', 'master & dynamic', \"levi's\", 'paa',\n",
       "       'han kjobenhavn', 'common projects', 'nasaseasons', 'raen',\n",
       "       'nudie jeans', 'master-piece co', 'cottweiler', 'axel arigato',\n",
       "       'enfants riches déprimés', 'ugo cacciatori', 'n.hoolywood',\n",
       "       'fear of god', 'gentle monster', 'robert geller', 'lemaire',\n",
       "       'song for the mute', 'y/project', 'vetements', 'neighborhood',\n",
       "       'we11done', 'gmbh', 'undercover', 'ann demeulemeester', 'harmony',\n",
       "       'giuseppe zanotti', 'polythene* optics', 'kiko kostadinov',\n",
       "       'sacai', 'faith connexion', 'julius', 'dries van noten', 'misbhv',\n",
       "       'martine rose', 'bless', \"d'heygere\", 'martyre', 'unravel',\n",
       "       'isabel benenato', 'wacko maria', 'sasquatchfabrix.', 'balmain',\n",
       "       'nanamica', 'botter', 'phipps', 'pearls before swine', 'sunspel',\n",
       "       'viu', 'noon goons', 'valextra', 'jan-jan van essche',\n",
       "       'alexander wang', 'stay made', 'pierre hardy', 'reese cooper',\n",
       "       'erl', 'oberkampf', 'spencer badu', 'doublet', 'christian dada',\n",
       "       'kang dong', 'msgm', 'www.willshott', 'yang li', 'paria /farzaneh',\n",
       "       'alanui', 'maximum henry', 'goodfight', 'north face',\n",
       "       'perks and mini', 'needles', 'minotaur', 'oamc', 'linder',\n",
       "       'stella mccartney', 'retrosuperfuture', 'xander zhou',\n",
       "       'afterhomework', 'bed j.w. ford', 'matthew adams dolan',\n",
       "       'the viridi-anne', 'nonnative', 'lanvin', 'st-henri',\n",
       "       'second/layer', 'name.', 'charles jeffrey loverboy',\n",
       "       'johnlawrencesullivan', 'engineered garments', 'martin asbjorn',\n",
       "       'isabel marant', 'judy turner', 'kozaburo', 'eckhaus latta',\n",
       "       'missoni', 'brioni', 'tibi', 'alain mikli paris', 'feng chen wang',\n",
       "       'toogood', 'nor', 'kassl editions', 'sulvam', 'bode', 'all blues',\n",
       "       'champion reverse weave', 'garrett leight', 'agr',\n",
       "       'haider ackermann', 'liam hodges', 'cmmn swdn', 'bunney',\n",
       "       'roberi & fraud', 'native sons', 'abasi rosborough', 'gr10k',\n",
       "       'diesel', 'our legacy', 'district vision', 'nahmias', 'innerraum',\n",
       "       'serapis', 'band of outsiders', 'luka sabbat x monini', 'deepti',\n",
       "       '99% is', 'lool', 'blyszak', 'belstaff', 'hope', 'golden goose',\n",
       "       'eastpak', 'côte & ciel', 'kiko kostadinov,asics',\n",
       "       'officine creative', 'heliot emil', '3.1 phillip lim', 'li-ning',\n",
       "       'sunnei', 'a. a. spectrum', 'sankuanz', 'wooyoungmi', 'marsèll',\n",
       "       'ribeyron', 'camiel fortgens', 'canada goose', 'essentials',\n",
       "       'solid & striped', 'frame', 'rochambeau', 'the very warm',\n",
       "       'craig green', \"l'homme rouge\", 's.r. studio. la. ca.', 'converse',\n",
       "       'stutterheim', 'cobra s.c.', 'barena', '49winters', 'sies marjan',\n",
       "       'ksubi', 'adidas,missoni', 'pyer moss', 'mowalola', 'helmut lang',\n",
       "       'vyner articles', 'who decides war by mrdr brvdo', 'john elliott',\n",
       "       'naked & famous denim', 'nobis', 'calvin klein', 'all in',\n",
       "       'dickies construct', 'casablanca', 'harris wharf london', 'kanuk',\n",
       "       'bather', 'schott', 'vilebrequin', 'lacoste', 'hot mess',\n",
       "       'yves salomon', 'herno', 'descente allterrain', 'billy',\n",
       "       'parajumpers', 'nanushka', 'gcds', 'junya watanabe',\n",
       "       'everest isles', 'woolrich', 'sss world corp', 'ottolinger',\n",
       "       'worstok', 'moussy vintage', 'greg lauren', 'mr & mrs italy',\n",
       "       'warren lotas', 'studio nicholson', 'almostblack',\n",
       "       'filling pieces', 'miharayasuhiro', 'chen peng', 'hed mayner',\n",
       "       'namacheko', 'wales bonner', 'palomo spain', 'mackintosh',\n",
       "       \"schnayderman's\", 'eytys', 'eidos', 'stefan cooke', 'kuro',\n",
       "       'joseph', 'adaptation', 'kanghyuk', 'bianca saunders',\n",
       "       'post archive faction (paf)', 'deveaux new york', 'resort corps',\n",
       "       'remi relief', 'lqqk studio for paul & shark', 'telfar', 'wonders',\n",
       "       'keenkee', 'onia', 'vier', 'ziggy chen',\n",
       "       'colmar a.g.e. by shayne oliver', 'asics', 'mugler', 'blackmerle',\n",
       "       'baja east', 'anton belinskiy', 'house of the very islands',\n",
       "       'd by d', 'ahluwalia studio', 'simon miller', 'gosha rubchinskiy',\n",
       "       'childs', 'a_plan_application', 'diet butcher slim skin',\n",
       "       'chin mens', 'jeanerica', 'blondey', 'kwaidan editions', 'versus',\n",
       "       'nomenklatura studio', 'éditions m.r', 'facetasm', 'lad musician',\n",
       "       'wheir bobson', 'stephan schneider', 'vans', 'b sides', 'both',\n",
       "       '424,adidas', 'junya watanabe,new balance', 'dr. martens',\n",
       "       'suicoke', 'c2h4,asics', 'new balance', 'athletics footwear',\n",
       "       'toga virilis', 'r.m. williams', 'salomon',\n",
       "       'boris bidjan saberi,salomon', 'diemme', 'roa', 'ion',\n",
       "       'article no.', \"church's\", 'clarks originals', 'feit', 'spalwart',\n",
       "       'etq amsterdam', 'castañer', 'aprix', 'malibu sandals',\n",
       "       'hender scheme', 'h by hudson', 'harmony,asics'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['brand'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       032c  1017 alyx 9sm  3.1 phillip lim  424  49winters  99% is  \\\n",
      "0         0              0                0    0          0       0   \n",
      "1         0              0                0    0          0       0   \n",
      "2         0              0                0    0          0       0   \n",
      "3         0              0                0    0          0       0   \n",
      "4         0              0                0    0          0       0   \n",
      "...     ...            ...              ...  ...        ...     ...   \n",
      "28987     0              0                0    0          0       0   \n",
      "28988     0              0                0    0          0       0   \n",
      "28989     0              0                0    0          0       0   \n",
      "28990     0              0                0    0          0       0   \n",
      "28991     0              0                0    0          0       0   \n",
      "\n",
      "       a-cold-wall*  a. a. spectrum  a.p.c.  a_plan_application  ...  \\\n",
      "0                 0               0       0                   0  ...   \n",
      "1                 0               0       0                   0  ...   \n",
      "2                 0               0       0                   0  ...   \n",
      "3                 0               0       0                   0  ...   \n",
      "4                 0               0       0                   0  ...   \n",
      "...             ...             ...     ...                 ...  ...   \n",
      "28987             0               0       0                   0  ...   \n",
      "28988             0               0       0                   0  ...   \n",
      "28989             0               0       0                   0  ...   \n",
      "28990             0               0       0                   0  ...   \n",
      "28991             0               0       0                   0  ...   \n",
      "\n",
      "       xander zhou  y/project  yang li  yohji yamamoto  yuichi toyama  \\\n",
      "0                0          0        0               0              0   \n",
      "1                0          0        0               0              0   \n",
      "2                0          0        0               0              0   \n",
      "3                0          0        0               0              0   \n",
      "4                0          0        0               0              0   \n",
      "...            ...        ...      ...             ...            ...   \n",
      "28987            0          0        0               0              0   \n",
      "28988            0          0        0               0              0   \n",
      "28989            0          0        0               0              0   \n",
      "28990            0          0        0               0              0   \n",
      "28991            0          0        0               0              0   \n",
      "\n",
      "       yves salomon  zegna  ziggy chen  éditions m.r  études  \n",
      "0                 0      0           0             0       0  \n",
      "1                 0      0           0             0       0  \n",
      "2                 0      0           0             0       0  \n",
      "3                 0      0           0             0       0  \n",
      "4                 0      0           0             0       0  \n",
      "...             ...    ...         ...           ...     ...  \n",
      "28987             0      0           0             0       0  \n",
      "28988             0      0           0             0       0  \n",
      "28989             0      0           0             0       0  \n",
      "28990             0      0           0             0       0  \n",
      "28991             0      0           0             0       0  \n",
      "\n",
      "[28992 rows x 397 columns]\n"
     ]
    }
   ],
   "source": [
    "brand_mlb = MultiLabelBinarizer()\n",
    "\n",
    "brand_matrix = pd.DataFrame(brand_mlb.fit_transform(data['brand'].str.split(',')),columns=brand_mlb.classes_, index=data.index)\n",
    "\n",
    "print(brand_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name & Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal for these 2 columns are similar: removing stopwords, punctuations, lemmatizing and vectorizing them. Then at the same time, extracting colors of of these 2 fields. In fact, these 2 fields could be combined together into one single column as they both contains detail of a product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Black Short Bunny Echo BeanieRib knit cashmere...\n",
       "1        Red Wool Zebra BeanieRib knit lambswool beanie...\n",
       "2        Black Wool Zebra BeanieRib knit lambswool bean...\n",
       "3        Black Pouch iPhone CaseGrained leather shoulde...\n",
       "4        Silver Key NecklaceCurb chain necklace in ster...\n",
       "                               ...                        \n",
       "28987    Grey & Silver Asics Edition Gel-Kayano 25 Snea...\n",
       "28988    Black Yearling BootsHandcrafted ankle-high buf...\n",
       "28989    Black Crush Back LoafersGrained leather slip-o...\n",
       "28990    Black No Cap Boat SneakersVegetable-tanned buf...\n",
       "28991    Black Luis Mixed OxfordsPanelled buffed calfsk...\n",
       "Name: text_detail, Length: 28992, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text_detail'] = data['name'] + data['description']\n",
    "\n",
    "data['text_detail']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform the following steps:\n",
    "\n",
    "- Tokenization: Split the text into sentences and the sentences into words. Lowercase the words and remove punctuation.\n",
    "- Words that have fewer than 2 characters are removed.\n",
    "- All stopwords are removed.\n",
    "- Words are lemmatized — words in third person are changed to first person and verbs in past and future tenses are changed into present.\n",
    "- Words are stemmed — words are reduced to their root form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    text= re.sub(\"(\\r|\\n|-|&|approx|supplier|length|height)+\",\" \",text,flags=re.IGNORECASE) \n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 2:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return \" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Black Bee Card HolderTextured leather card holder in black. Logo stamp in gold-tone and signature hardware at face. Four card slots and one note slot. Tonal textile lining. Antiqued gold-tone hardware. Approx. 4\" length x 3\" height.\\r\\n\\r\\nSupplier color: Black'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sample = data.loc[2343,'text_detail']\n",
    "text_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text: \n",
      "['Black', 'Bee', 'Card', 'HolderTextured', 'leather', 'card', 'holder', 'in', 'black.', 'Logo', 'stamp', 'in', 'gold-tone', 'and', 'signature', 'hardware', 'at', 'face.', 'Four', 'card', 'slots', 'and', 'one', 'note', 'slot.', 'Tonal', 'textile', 'lining.', 'Antiqued', 'gold-tone', 'hardware.', 'Approx.', '4\"', 'length', 'x', '3\"', 'height.\\r\\n\\r\\nSupplier', 'color:', 'Black']\n",
      "\n",
      "\n",
      " tokenized and lemmatized text: \n",
      "black bee card holdertextur leather card holder black logo stamp gold tone signatur hardwar face card slot note slot tonal textil line antiqu gold tone hardwar color black\n"
     ]
    }
   ],
   "source": [
    "print('original text: ')\n",
    "words = []\n",
    "for word in text_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized text: ')\n",
    "print(preprocess(text_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    black short bunni echo beanierib knit cashmer ...\n",
       "1    red wool zebra beanierib knit lambswool beani ...\n",
       "2    black wool zebra beanierib knit lambswool bean...\n",
       "3    black pouch iphon casegrain leather shoulder b...\n",
       "4    silver key necklacecurb chain necklac sterl si...\n",
       "5    black perf beltbuf calfskin belt black tonal t...\n",
       "6    beig perfor logo beltbuf calfskin belt beig pe...\n",
       "7    revers white logo beltrevers buff calfskin bel...\n",
       "8    white buckl beltgrain leather belt white signa...\n",
       "9    silver watch strap braceletsteel oyster link b...\n",
       "Name: text_detail, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_detail = data['text_detail'].map(preprocess)\n",
    "processed_detail[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will extract color from the processed text so color would have its own feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_color(color): #to check if a word is color\n",
    "    try:\n",
    "        Color(color)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    except AttributeError:\n",
    "        return False\n",
    "\n",
    "def get_color(text): #to extract colors from text\n",
    "    \n",
    "    if [i for i in text.split(' ') if check_color(i)]:\n",
    "        return list(set([i for i in text.split(' ') if check_color(i)]))\n",
    "    else: #return 'other' if nothing matches\n",
    "        return ['other']\n",
    "\n",
    "def remove_color(text): #to remove colors from text\n",
    "    return \" \".join([i for i in text.split(\" \") if check_color(i) == False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = processed_detail.map(lambda x: get_color(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_detail = processed_detail.map(lambda x: remove_color(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic Modelling based on Processed Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of terms included in the bag of words matrix is restricted to the top 1000 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_features = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accent', 'accordion', 'ace', 'acet', 'achill', 'acid', 'acn', 'adida', 'adjust', 'aglet']\n"
     ]
    }
   ],
   "source": [
    "# NMF is able to use tf-idf  because it is a linear-algeabreic model\n",
    "\n",
    "tfidf_vectorizer_model = TfidfVectorizer(max_df=0.95, min_df=2, max_features=no_features) #Model to transform new text \n",
    "tfidf_matrix = tfidf_vectorizer_model.fit_transform(processed_detail)\n",
    "\n",
    "tfidf_feature_names = tfidf_vectorizer_model.get_feature_names()\n",
    "print(tfidf_feature_names[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accent', 'accordion', 'ace', 'acet', 'achill', 'acid', 'acn', 'adida', 'adjust', 'aglet']\n"
     ]
    }
   ],
   "source": [
    "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model\n",
    "\n",
    "tf_vectorizer_model = CountVectorizer(max_df=0.95, min_df=2, max_features=no_features) #Model to transform new text \n",
    "tf_matrix = tf_vectorizer_model.fit_transform(processed_detail)\n",
    "\n",
    "tf_feature_names = tf_vectorizer_model.get_feature_names()\n",
    "print(tf_feature_names[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are limiting the number of topics both NMF and LDA models can generate to 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_topics = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_columns = []\n",
    "\n",
    "for i in range(no_topics):\n",
    "    topic_columns.append(f\"Topic {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.39523667e-05 0.00000000e+00 0.00000000e+00 ... 2.83745713e-04\n",
      "  0.00000000e+00 5.24625643e-02]\n",
      " [5.31523504e-05 0.00000000e+00 0.00000000e+00 ... 3.42108803e-04\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 1.90640147e-02 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.52338802e-02 ... 2.00106552e-03\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 3.40462123e-02 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Run NMF\n",
    "nmf_model = NMF(n_components=no_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd')\n",
    "nmf_matrix = nmf_model.fit_transform(tfidf_matrix)\n",
    "\n",
    "print(nmf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00222222 0.00222222 0.65610898 ... 0.00222222 0.00222222 0.00222222]\n",
      " [0.00133333 0.00133333 0.65874463 ... 0.00133333 0.00133333 0.00133333]\n",
      " [0.00133333 0.00133333 0.66004566 ... 0.00133333 0.00133333 0.00133333]\n",
      " ...\n",
      " [0.00142857 0.07353551 0.00142857 ... 0.07147497 0.07725732 0.00142857]\n",
      " [0.00095238 0.09680466 0.00095238 ... 0.11455262 0.07639048 0.00095238]\n",
      " [0.03887789 0.03402103 0.00066667 ... 0.07403356 0.00066667 0.00066667]]\n"
     ]
    }
   ],
   "source": [
    "# Run LDA\n",
    "lda_model = LatentDirichletAllocation(n_components =no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0)\n",
    "ldf_matrix = lda_model.fit_transform(tf_matrix)\n",
    "\n",
    "print(ldf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:{}\n",
      "shirtshort jersey shirt crewneck cotton rib sleev knit collar chest\n",
      "Topic 1:{}\n",
      "fli trouser fit belt waistband rise mid trousersslim loop zip\n",
      "Topic 2:{}\n",
      "rubber pad heel sneaker lace tread tongu round toe sneakerslow\n",
      "Topic 3:{}\n",
      "button barrel spread singl shirtlong shirt shirttail closur poplin cuff\n",
      "Topic 4:{}\n",
      "compart face zipper strap width web main shoulder adjust interior\n",
      "Topic 5:{}\n",
      "hoodi hoodielong hood kangaroo drawstr terri french waist hem rib\n",
      "Topic 6:{}\n",
      "knit sweater sweaterlong rib hem crewneck sleev cuff collar turtleneck\n",
      "Topic 7:{}\n",
      "templ size nose acet case includ lens sunglass metal protect\n",
      "Topic 8:{}\n",
      "navi dark midnight colorblock ink cotton color flag stripe tiesilk\n",
      "Topic 9:{}\n",
      "slot bifold wallet note emboss interior card width face textil\n",
      "Topic 10:{}\n",
      "loung pant elastic fit drawstr waistband mid rise style pantsrelax\n",
      "Topic 11:{}\n",
      "card slot holder face note holderbuf calfskin holdergrain textil stamp\n",
      "Topic 12:{}\n",
      "multicolor graphic multi zebra print tiger appliqué wing featur floral\n",
      "Topic 13:{}\n",
      "denim stretch jean fade contrast non waistband distress tone whisker\n",
      "Topic 14:{}\n",
      "stud press fasten flap post placket conceal hardwar releas adjust\n",
      "Topic 15:{}\n",
      "sweatshirt sweatshirtlong terri french crewneck hem rib cuff knit sleev\n",
      "Topic 16:{}\n",
      "embroid logo chest appliqué graphic text fleec script tonal colorblock\n",
      "Topic 17:{}\n",
      "welt button pocket lapel notch blazer vent waist surgeon blazerlong\n",
      "Topic 18:{}\n",
      "ssens exclus avail photo zebra capsul regular organ tag primaloft\n",
      "Topic 19:{}\n",
      "tonal stitch hardwar trim topstitch nylon overlock detail line weav\n",
      "Topic 20:{}\n",
      "beig archiv canva trim suprem cotton camel sued twill eboni\n",
      "Topic 21:{}\n",
      "short swim elastic drawstr waistband rise mid style mesh pocket\n",
      "Topic 22:{}\n",
      "check pattern flannel featur plaid tone houndstooth weav shirttail archiv\n",
      "Topic 23:{}\n",
      "print graphic text logo edit tone collabor color flag signatur\n",
      "Topic 24:{}\n",
      "polo piqué placket poloshort seam vent spread button sleev cotton\n",
      "Topic 25:{}\n",
      "knit sock blend sockscalf high stretch rib cotton logo jacquard\n",
      "Topic 26:{}\n",
      "chain clasp fasten lobster necklac link pendant sterl bracelet lanyard\n",
      "Topic 27:{}\n",
      "jacket jacketlong zip waist stand pocket welt closur sleev bomber\n",
      "Topic 28:{}\n",
      "orang text clockwork colorblock textil heron contrast web fluo bright\n",
      "Topic 29:{}\n",
      "featur pattern jacquard floral graphic tone open camouflag trim camo\n",
      "Topic 30:{}\n",
      "drop shoulder tail inseam pendant earring hem necklac crop hoop\n",
      "Topic 31:{}\n",
      "purpl colorblock fleec turtleneck turtlenecklong tone graphic flower velour seam\n",
      "Topic 32:{}\n",
      "brim cap eyelet crown face twill capcotton cinch curv beani\n",
      "Topic 33:{}\n",
      "buckl pin adjust fasten belt hardwar tone beltbuf calfskin strap\n",
      "Topic 34:{}\n",
      "long shirtlong sleev shirt jersey crewneck cotton collar rib knit\n",
      "Topic 35:{}\n",
      "patch logo textil pocket flag chest rubber seam appliqué interior\n",
      "Topic 36:{}\n",
      "strip signatur stripe tricolor grosgrain flag featur trim bar outseam\n",
      "Topic 37:{}\n",
      "boot chelsea heel bootsankl high pull toe loop gusset sued\n",
      "Topic 38:{}\n",
      "wool blend virgin merino mohair color scarf beani trouser roll\n",
      "Topic 39:{}\n",
      "leather sole buff toe line loafer vamp round grain stack\n",
      "Topic 40:{}\n",
      "tie dye silk tiesilk twill keeper width garment self loop\n",
      "Topic 41:{}\n",
      "cashmer blend scarf fring end knit beani color detail glove\n",
      "Topic 42:{}\n",
      "edg raw hem tank expos seam detail panel armscy burnish\n",
      "Topic 43:{}\n",
      "track elastic pant technic outseam pantsrelax nylon cuff jersey fit\n",
      "Topic 44:{}\n",
      "nylon bunge zipper drawstr quilt hood satin fill feather style\n",
      "Topic 45:{}\n",
      "leg fli rise waistband trouser style mid cargo pocket crop\n",
      "Topic 46:{}\n",
      "engrav ring band sterl detail face inner logo carv ringband\n",
      "Topic 47:{}\n",
      "boxer brief elastic medusa jersey briefsstretch waistband pack greek low\n",
      "Topic 48:{}\n",
      "neck mock cardigan cardiganlong tank knit collar funnel rib topsleeveless\n",
      "Topic 49:{}\n",
      "burgundi bordeaux colorblock trim color weav cherri corduroy appliqué flag\n"
     ]
    }
   ],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print (\"Topic %d:{}\" % (topic_idx))\n",
    "        print (\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "\n",
    "no_top_words = 10\n",
    "\n",
    "display_topics(nmf_model, tfidf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:{}\n",
      "strip orang signatur pull grosgrain stripe textil flag tricolor featur\n",
      "Topic 1:{}\n",
      "round sculpt core expos japanes clear leather wire ash color\n",
      "Topic 2:{}\n",
      "wool color blend virgin knit almond roll turtleneck turtlenecklong merino\n",
      "Topic 3:{}\n",
      "central face logo burgundi slot card color interior line textil\n",
      "Topic 4:{}\n",
      "shirt shirtshort crewneck pleat shirtlong garment asic tail chalk lyocel\n",
      "Topic 5:{}\n",
      "outer inner stack textur band color ring block logo stamp\n",
      "Topic 6:{}\n",
      "gunmet metal inset tone iridesc parkalong parka coyot plastic structur\n",
      "Topic 7:{}\n",
      "detail pale fine noir flip jacron oyster marin extra palladium\n",
      "Topic 8:{}\n",
      "sleev collar hem chest seam hood drawstr stand poplin neck\n",
      "Topic 9:{}\n",
      "pad mesh semi oxford runner mould eastpak backpackwat transpar backpack\n",
      "Topic 10:{}\n",
      "welt jacket jacketlong spread blazer blazerlong track armscy poloshort konst\n",
      "Topic 11:{}\n",
      "stitch tonal belt tone denim hardwar contrast logo antiqu topstitch\n",
      "Topic 12:{}\n",
      "fli loop twill fade silk color floral whisker jeansslim jeansskinni\n",
      "Topic 13:{}\n",
      "loung terri french hoodi hoodielong low sweatshirt sweatshirtlong pantsrelax crewneck\n",
      "Topic 14:{}\n",
      "pant drop chain color logo fasten tone clasp sterl lobster\n",
      "Topic 15:{}\n",
      "press stud fasten jean releas nylon colorblock mold logo adjust\n",
      "Topic 16:{}\n",
      "edg cashmer swoosh viscos flannel brush blend color natur herringbon\n",
      "Topic 17:{}\n",
      "tread edit collabor reflect open patent lightweight transluc accent tone\n",
      "Topic 18:{}\n",
      "pocket closur zip patch hardwar tonal lace line zipper tone\n",
      "Topic 19:{}\n",
      "sued text stitch print distress raw tonal subtl overlock terrycloth\n",
      "Topic 20:{}\n",
      "integr tortoiseshel inject polar havana pari templ acet pad size\n",
      "Topic 21:{}\n",
      "waistband mid drawstr leg stretch logo short cotton color jacquard\n",
      "Topic 22:{}\n",
      "navi polo fur pattern closur medusa box color signatur greek\n",
      "Topic 23:{}\n",
      "knit rib cuff color crewneck sweater blend sweaterlong fleec wool\n",
      "Topic 24:{}\n",
      "web strap logo adjust fasten face trim hardwar color detach\n",
      "Topic 25:{}\n",
      "elastic graphic print multicolor jersey color featur side bond signatur\n",
      "Topic 26:{}\n",
      "star nubuck backpack laptop fujiwara hiroshi backpacknylon oil easi war\n",
      "Topic 27:{}\n",
      "faux non smudg layer paint effect jeansstraight skinni materi splatter\n",
      "Topic 28:{}\n",
      "crepe tank topsleeveless van gather bowl hawaiian scoop sunspel linda\n",
      "Topic 29:{}\n",
      "button cuff cotton color stretch blend surgeon doubl featur twin\n",
      "Topic 30:{}\n",
      "logo hardwar tone engrav plaqu dark cut color featur oliv\n",
      "Topic 31:{}\n",
      "leather tonal emboss signatur calfskin line grain stamp color logo\n",
      "Topic 32:{}\n",
      "trouser trousersslim air waistband creas crop trouserstap locker trousersrelax crinkl\n",
      "Topic 33:{}\n",
      "logo collar heel toe color cotton knit jersey sole rib\n",
      "Topic 34:{}\n",
      "pattern featur beig canva check tone trim vintag houndstooth weav\n",
      "Topic 35:{}\n",
      "water hand technolog throat resist crystal flat run steel quarter\n",
      "Topic 36:{}\n",
      "placket pololong adida urban duffl pen level briefcas bagtechn bagcoat\n",
      "Topic 37:{}\n",
      "polish croc cleav wrap gaug teal shortsquick wraparound color fasten\n",
      "Topic 38:{}\n",
      "flap pouch foldov cloth magnet drawstr rugbi clean pure twin\n",
      "Topic 39:{}\n",
      "vent fit tonal logo embroid style drawstr hardwar technic bunge\n",
      "Topic 40:{}\n",
      "rise style singl cuff lapel partial copper color velour hybrid\n",
      "Topic 41:{}\n",
      "boot ssens exclus notch avail slim util neopren convert tabi\n",
      "Topic 42:{}\n",
      "spread barrel shirtlong shirttail light leopard straight yoke hair point\n",
      "Topic 43:{}\n",
      "waist outseam gusset vest messeng pinstrip vestsleeveless storm bodi baggrain\n",
      "Topic 44:{}\n",
      "perfor hardwar tone adjust fasten tab buckl pin color stud\n",
      "Topic 45:{}\n",
      "sneaker conceal shoulder panel foam bond ripstop carri velcro pocket\n",
      "Topic 46:{}\n",
      "purpl tie self regular bordeaux slit fox wax colorblock sequin\n",
      "Topic 47:{}\n",
      "rubber trim logo featur buff loop tonal appliqué tone dye\n",
      "Topic 48:{}\n",
      "slip includ logo templ size pad case color nose acet\n",
      "Topic 49:{}\n",
      "coat construct wash funnel trench gradient matt vinyl glossi liner\n"
     ]
    }
   ],
   "source": [
    "display_topics(lda_model, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now build a function to return topic with highest weight for a new text to test both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nmf_topic(text, features, no_top_words):\n",
    "    text  = pd.Series(text).apply(preprocess).apply(remove_color)\n",
    "    matrix = nmf_model.components_[np.argmax(nmf_model.transform(tfidf_vectorizer_model.transform(text)))]\n",
    "    \n",
    "    return [features[i] for i in matrix.argsort()[:-no_top_words-1:-1]]\n",
    "\n",
    "def get_lda_topic(text, features, no_top_words):\n",
    "    text  = pd.Series(text).apply(preprocess).apply(remove_color)\n",
    "    matrix = lda_model.components_[np.argmax(lda_model.transform(tf_vectorizer_model.transform(text)))]\n",
    "    \n",
    "    return [features[i] for i in matrix.argsort()[:-no_top_words-1:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neck',\n",
       " 'mock',\n",
       " 'cardigan',\n",
       " 'cardiganlong',\n",
       " 'tank',\n",
       " 'knit',\n",
       " 'collar',\n",
       " 'funnel',\n",
       " 'rib',\n",
       " 'topsleeveless']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text_1 = '''\n",
    "burgundy wool crew neck panelled jumper from E. Tautz \n",
    "featuring a ribbed crew neck, long sleeves, elasticated cuffs, \n",
    "a panelled colour block design and a relaxed fit.\n",
    "'''\n",
    "get_nmf_topic(sample_text_1, tfidf_feature_names, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logo',\n",
       " 'collar',\n",
       " 'heel',\n",
       " 'toe',\n",
       " 'color',\n",
       " 'cotton',\n",
       " 'knit',\n",
       " 'jersey',\n",
       " 'sole',\n",
       " 'rib']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lda_topic(sample_text_1, tf_feature_names, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['compart',\n",
       " 'face',\n",
       " 'zipper',\n",
       " 'strap',\n",
       " 'width',\n",
       " 'web',\n",
       " 'main',\n",
       " 'shoulder',\n",
       " 'adjust',\n",
       " 'interior']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text_2 = '''\n",
    "Long sleeve stone wash calfskin jacket in black. \n",
    "Spread collar. Offset zip closure. Zippered pocket at chest. \n",
    "Zippered pockets and flap pocket at waist. Detachable epaulets \n",
    "featuring chain-link detailing with press-stud fastenings. Zippered \n",
    "vent at cuffs. Darts and tonal webbing carry handle-style trim at back. \n",
    "Zippered pockets at interior. Lined. Silver-tone hardware.\n",
    "Supplier color: Black\n",
    "'''\n",
    "get_nmf_topic(sample_text_2, tfidf_feature_names, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pocket',\n",
       " 'closur',\n",
       " 'zip',\n",
       " 'patch',\n",
       " 'hardwar',\n",
       " 'tonal',\n",
       " 'lace',\n",
       " 'line',\n",
       " 'zipper',\n",
       " 'tone']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lda_topic(sample_text_2, tf_feature_names, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['templ',\n",
       " 'size',\n",
       " 'nose',\n",
       " 'acet',\n",
       " 'case',\n",
       " 'includ',\n",
       " 'lens',\n",
       " 'sunglass',\n",
       " 'metal',\n",
       " 'protect']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text_3 = '''\n",
    "Rectangular metal-frame sunglasses in gold-tone. \n",
    "Transparent rubber nose pads. Green ZEISS© lenses with\n",
    "100% UVA/UVB protection. Logo etched at temples. Tortoiseshell acetate temple \n",
    "tips in tones of brown. Size: 143.20 140.\n",
    "Supplier color: Gold/Green\n",
    "'''\n",
    "get_nmf_topic(sample_text_3, tfidf_feature_names, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['slip',\n",
       " 'includ',\n",
       " 'logo',\n",
       " 'templ',\n",
       " 'size',\n",
       " 'pad',\n",
       " 'case',\n",
       " 'color',\n",
       " 'nose',\n",
       " 'acet']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lda_topic(sample_text_3, tf_feature_names, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NMF model seems to generate more meaningful topics than LDA in this particular case. This doesn't mean LDA, matematically is a worse model compared to NMF but it is generally easier to guess the items based on the topics generated by NMF. Therefore, we will use NMF for the recommendation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Topic 0  Topic 1   Topic 2   Topic 3   Topic 4  Topic 5   Topic 6  \\\n",
      "0      0.000000      0.0  0.000000  0.000000  0.000000      0.0  0.004878   \n",
      "1      0.000084      0.0  0.000000  0.000000  0.000000      0.0  0.005051   \n",
      "2      0.000053      0.0  0.000000  0.000000  0.000000      0.0  0.005217   \n",
      "3      0.000000      0.0  0.000000  0.000000  0.031042      0.0  0.000000   \n",
      "4      0.000000      0.0  0.000440  0.000000  0.000000      0.0  0.000000   \n",
      "...         ...      ...       ...       ...       ...      ...       ...   \n",
      "28987  0.000000      0.0  0.062298  0.000000  0.000000      0.0  0.000000   \n",
      "28988  0.000000      0.0  0.000000  0.000000  0.000000      0.0  0.000000   \n",
      "28989  0.000000      0.0  0.019064  0.000000  0.000000      0.0  0.000000   \n",
      "28990  0.000000      0.0  0.025234  0.000000  0.000000      0.0  0.000000   \n",
      "28991  0.000000      0.0  0.034046  0.000882  0.000000      0.0  0.000000   \n",
      "\n",
      "        Topic 7  Topic 8   Topic 9  ...  Topic 40  Topic 41  Topic 42  \\\n",
      "0      0.000000  0.00000  0.000000  ...       0.0  0.074227       0.0   \n",
      "1      0.000000  0.00000  0.000000  ...       0.0  0.003192       0.0   \n",
      "2      0.000000  0.01876  0.000000  ...       0.0  0.003337       0.0   \n",
      "3      0.005719  0.00000  0.002712  ...       0.0  0.000000       0.0   \n",
      "4      0.000000  0.00000  0.003387  ...       0.0  0.000000       0.0   \n",
      "...         ...      ...       ...  ...       ...       ...       ...   \n",
      "28987  0.000163  0.00000  0.000000  ...       0.0  0.000000       0.0   \n",
      "28988  0.000000  0.00000  0.000000  ...       0.0  0.000000       0.0   \n",
      "28989  0.000000  0.00000  0.000000  ...       0.0  0.000000       0.0   \n",
      "28990  0.000000  0.00000  0.000000  ...       0.0  0.000000       0.0   \n",
      "28991  0.000000  0.00000  0.003322  ...       0.0  0.000000       0.0   \n",
      "\n",
      "       Topic 43  Topic 44  Topic 45  Topic 46  Topic 47  Topic 48  Topic 49  \n",
      "0      0.000000       0.0       0.0  0.000000  0.000000       0.0  0.000000  \n",
      "1      0.000000       0.0       0.0  0.000000  0.000284       0.0  0.052463  \n",
      "2      0.000000       0.0       0.0  0.000000  0.000342       0.0  0.000000  \n",
      "3      0.000000       0.0       0.0  0.011851  0.000000       0.0  0.000000  \n",
      "4      0.000000       0.0       0.0  0.000000  0.009763       0.0  0.000000  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "28987  0.000000       0.0       0.0  0.000000  0.000000       0.0  0.000000  \n",
      "28988  0.000808       0.0       0.0  0.000000  0.002468       0.0  0.000000  \n",
      "28989  0.000000       0.0       0.0  0.000000  0.000000       0.0  0.000000  \n",
      "28990  0.002055       0.0       0.0  0.000000  0.002001       0.0  0.000000  \n",
      "28991  0.001493       0.0       0.0  0.001955  0.000000       0.0  0.000000  \n",
      "\n",
      "[28992 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "topic_matrix = pd.DataFrame(nmf_matrix,columns=topic_columns, index=data.index)\n",
    "\n",
    "print(topic_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       aqua  black  blue  brown  coral  crimson  cyan  fuchsia  gold  gray  \\\n",
      "0         0      1     0      0      0        0     0        0     0     0   \n",
      "1         0      0     0      0      0        0     0        0     0     0   \n",
      "2         0      1     0      0      0        0     0        0     0     0   \n",
      "3         0      1     1      0      0        0     0        0     0     0   \n",
      "4         0      0     0      0      0        0     0        0     0     0   \n",
      "...     ...    ...   ...    ...    ...      ...   ...      ...   ...   ...   \n",
      "28987     0      1     0      0      0        0     0        0     0     0   \n",
      "28988     0      1     0      0      0        0     0        0     0     0   \n",
      "28989     0      1     0      1      0        0     0        0     0     0   \n",
      "28990     0      1     0      0      0        0     0        0     0     0   \n",
      "28991     0      1     0      0      0        0     0        0     0     0   \n",
      "\n",
      "       ...  salmon  sienna  silver  snow  tan  tomato  violet  wheat  white  \\\n",
      "0      ...       0       0       0     0    0       0       0      0      0   \n",
      "1      ...       0       0       0     0    0       0       0      0      0   \n",
      "2      ...       0       0       0     0    0       0       0      0      0   \n",
      "3      ...       0       0       1     0    0       0       0      0      1   \n",
      "4      ...       0       0       1     0    0       0       0      0      0   \n",
      "...    ...     ...     ...     ...   ...  ...     ...     ...    ...    ...   \n",
      "28987  ...       0       0       1     0    0       0       0      0      1   \n",
      "28988  ...       0       0       0     0    0       0       0      0      0   \n",
      "28989  ...       0       0       0     0    1       0       0      0      0   \n",
      "28990  ...       0       0       0     0    1       0       0      0      0   \n",
      "28991  ...       0       0       0     0    0       0       0      0      0   \n",
      "\n",
      "       yellow  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n",
      "...       ...  \n",
      "28987       0  \n",
      "28988       0  \n",
      "28989       0  \n",
      "28990       0  \n",
      "28991       0  \n",
      "\n",
      "[28992 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "color_mlb = MultiLabelBinarizer()\n",
    "\n",
    "color_matrix = color_mlb.fit_transform(colors)\n",
    "\n",
    "color_matrix = pd.DataFrame(color_matrix ,columns = color_mlb.classes_, index = data.index)\n",
    "\n",
    "print(color_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Australia  Austria  Belgium  Canada  Denmark  France  Germany  \\\n",
      "0              0        0        0       0        0       0        0   \n",
      "1              0        0        0       0        0       0        0   \n",
      "2              0        0        0       0        0       0        0   \n",
      "3              0        0        0       0        0       0        0   \n",
      "4              0        0        0       0        0       0        0   \n",
      "...          ...      ...      ...     ...      ...     ...      ...   \n",
      "28987          0        0        0       0        0       0        0   \n",
      "28988          1        0        0       0        0       0        0   \n",
      "28989          0        0        0       0        0       0        0   \n",
      "28990          0        0        0       0        0       0        0   \n",
      "28991          0        0        0       0        0       0        0   \n",
      "\n",
      "       Imported  Italy  Japan  Morocco  Netherlands  Portugal  South Korea  \\\n",
      "0             0      0      0        0            0         0            0   \n",
      "1             0      0      0        0            0         0            0   \n",
      "2             0      0      0        0            0         0            0   \n",
      "3             0      1      0        0            0         0            0   \n",
      "4             0      1      0        0            0         0            0   \n",
      "...         ...    ...    ...      ...          ...       ...          ...   \n",
      "28987         1      0      0        0            0         0            0   \n",
      "28988         0      0      0        0            0         0            0   \n",
      "28989         0      1      0        0            0         0            0   \n",
      "28990         0      1      0        0            0         0            0   \n",
      "28991         0      1      0        0            0         0            0   \n",
      "\n",
      "       Spain  Sweden  Switzerland  United Kingdom  United States  \n",
      "0          0       0            0               0              1  \n",
      "1          0       0            0               1              0  \n",
      "2          0       0            0               1              0  \n",
      "3          0       0            0               0              0  \n",
      "4          0       0            0               0              0  \n",
      "...      ...     ...          ...             ...            ...  \n",
      "28987      0       0            0               0              0  \n",
      "28988      0       0            0               0              0  \n",
      "28989      0       0            0               0              0  \n",
      "28990      0       0            0               0              0  \n",
      "28991      0       0            0               0              0  \n",
      "\n",
      "[28992 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "origin_mlb = MultiLabelBinarizer()\n",
    "\n",
    "origin_matrix = origin_mlb.fit_transform(data['origin'].str.split(','))\n",
    "\n",
    "origin_matrix = pd.DataFrame(origin_matrix ,columns = origin_mlb.classes_, index = data.index)\n",
    "\n",
    "print(origin_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Material Composition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Composition text is a bit easier to process as we are disregarding the percentage, all the number inside and only want the name of the material. Specific items like jackets, shoes have words like Upper, Sole, Body, Trim, etc. in the composition text that are not related to material. To identify those words is a manual sampling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_composition(text):\n",
    "    text= re.sub(\"(Upper|Sole|Body|Trim|Lining|Fill|American)\",\" \",text,flags=re.IGNORECASE) \n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 2:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return \" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         [cashmer]\n",
       "1                       [lambswool]\n",
       "2                       [lambswool]\n",
       "3                         [leather]\n",
       "4                   [sterl, silver]\n",
       "                    ...            \n",
       "28987              [textil, rubber]\n",
       "28988                     [leather]\n",
       "28989             [leather, rubber]\n",
       "28990            [calfskin, rubber]\n",
       "28991    [calfskin, textil, rubber]\n",
       "Name: composition, Length: 28992, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_composition = data['composition'].astype(str).apply(process_composition).str.split()\n",
    "\n",
    "processed_composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       aceat  acet  acid  acryl  agat  alloy  alpaca  aluminium  aluminum  \\\n",
      "0          0     0     0      0     0      0       0          0         0   \n",
      "1          0     0     0      0     0      0       0          0         0   \n",
      "2          0     0     0      0     0      0       0          0         0   \n",
      "3          0     0     0      0     0      0       0          0         0   \n",
      "4          0     0     0      0     0      0       0          0         0   \n",
      "...      ...   ...   ...    ...   ...    ...     ...        ...       ...   \n",
      "28987      0     0     0      0     0      0       0          0         0   \n",
      "28988      0     0     0      0     0      0       0          0         0   \n",
      "28989      0     0     0      0     0      0       0          0         0   \n",
      "28990      0     0     0      0     0      0       0          0         0   \n",
      "28991      0     0     0      0     0      0       0          0         0   \n",
      "\n",
      "       angora  ...  weav  wood  wool  yak  yarn  yellow  zamac  zamak  zinc  \\\n",
      "0           0  ...     0     0     0    0     0       0      0      0     0   \n",
      "1           0  ...     0     0     0    0     0       0      0      0     0   \n",
      "2           0  ...     0     0     0    0     0       0      0      0     0   \n",
      "3           0  ...     0     0     0    0     0       0      0      0     0   \n",
      "4           0  ...     0     0     0    0     0       0      0      0     0   \n",
      "...       ...  ...   ...   ...   ...  ...   ...     ...    ...    ...   ...   \n",
      "28987       0  ...     0     0     0    0     0       0      0      0     0   \n",
      "28988       0  ...     0     0     0    0     0       0      0      0     0   \n",
      "28989       0  ...     0     0     0    0     0       0      0      0     0   \n",
      "28990       0  ...     0     0     0    0     0       0      0      0     0   \n",
      "28991       0  ...     0     0     0    0     0       0      0      0     0   \n",
      "\n",
      "       zink  \n",
      "0         0  \n",
      "1         0  \n",
      "2         0  \n",
      "3         0  \n",
      "4         0  \n",
      "...     ...  \n",
      "28987     0  \n",
      "28988     0  \n",
      "28989     0  \n",
      "28990     0  \n",
      "28991     0  \n",
      "\n",
      "[28992 rows x 292 columns]\n"
     ]
    }
   ],
   "source": [
    "composition_mlb = MultiLabelBinarizer()\n",
    "\n",
    "composition_matrix = pd.DataFrame(composition_mlb.fit_transform(processed_composition),columns=composition_mlb.classes_, index=data.index)\n",
    "\n",
    "print(composition_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remaining Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0  00  1  10  10.5  10/12  100  105  11  11.5  ...  T  U  UNI  XL  \\\n",
      "0      0   0  0   0     0      0    0    0   0     0  ...  0  0    1   0   \n",
      "1      0   0  0   0     0      0    0    0   0     0  ...  0  0    1   0   \n",
      "2      0   0  0   0     0      0    0    0   0     0  ...  0  0    1   0   \n",
      "3      0   0  0   0     0      0    0    0   0     0  ...  0  0    1   0   \n",
      "4      0   0  0   0     0      0    0    0   0     0  ...  0  0    1   0   \n",
      "...   ..  .. ..  ..   ...    ...  ...  ...  ..   ...  ... .. ..  ...  ..   \n",
      "28987  0   0  0   0     0      0    0    0   0     0  ...  0  0    0   0   \n",
      "28988  0   0  0   0     0      0    0    0   0     0  ...  0  0    0   0   \n",
      "28989  0   0  0   0     0      0    0    0   0     0  ...  0  0    0   0   \n",
      "28990  0   0  0   0     0      0    0    0   0     0  ...  0  0    0   0   \n",
      "28991  0   0  0   0     0      0    0    0   0     0  ...  0  0    0   0   \n",
      "\n",
      "       XL/XXL  XS  XS/S  XXL  XXS  XXXL  \n",
      "0           0   0     0    0    0     0  \n",
      "1           0   0     0    0    0     0  \n",
      "2           0   0     0    0    0     0  \n",
      "3           0   0     0    0    0     0  \n",
      "4           0   0     0    0    0     0  \n",
      "...       ...  ..   ...  ...  ...   ...  \n",
      "28987       0   0     0    0    0     0  \n",
      "28988       0   0     0    0    0     0  \n",
      "28989       0   0     0    0    0     0  \n",
      "28990       0   0     0    0    0     0  \n",
      "28991       0   0     0    0    0     0  \n",
      "\n",
      "[28992 rows x 157 columns]\n"
     ]
    }
   ],
   "source": [
    "size_mlb = MultiLabelBinarizer()\n",
    "\n",
    "size_matrix = pd.DataFrame(size_mlb.fit_transform(data['remaining-sizes'].apply(ast.literal_eval)),columns=size_mlb.classes_, index=data.index)\n",
    "\n",
    "print(size_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we already established during the EDA process that prices are right skewed for both full and sale prices, a useful normalization for these values are log transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['full-price'] = data['full-price'].map(np.log)\n",
    "data['sale-price'] = data['sale-price'].map(np.log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting Everything Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we combine all matrices with new features we have created earlier into a single new dataframe for the recommendation system to train on later. We include the SKU numbers in the dataframe so the specific product can be looked up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 sku  accessories  backpacks  bags  bars  beanies  belts  \\\n",
      "0      201014M138001            0          0     0     0        1      0   \n",
      "1      201422M138012            0          0     0     0        1      0   \n",
      "2      201422M138013            0          0     0     0        1      0   \n",
      "3      201168M170261            0          0     0     0        0      0   \n",
      "4      201168M145213            0          0     0     0        0      0   \n",
      "...              ...          ...        ...   ...   ...      ...    ...   \n",
      "28987  191678M237003            0          0     0     0        0      0   \n",
      "28988  191993M223011            0          0     0     0        0      0   \n",
      "28989  191358M237006            0          0     0     0        0      0   \n",
      "28990  191232M237005            0          0     0     0        0      0   \n",
      "28991  181813M225005            0          0     0     0        0      0   \n",
      "\n",
      "       biker  blankets  blazers  ...  UNI  XL  XL/XXL  XS  XS/S  XXL  XXS  \\\n",
      "0          0         0        0  ...    1   0       0   0     0    0    0   \n",
      "1          0         0        0  ...    1   0       0   0     0    0    0   \n",
      "2          0         0        0  ...    1   0       0   0     0    0    0   \n",
      "3          0         0        0  ...    1   0       0   0     0    0    0   \n",
      "4          0         0        0  ...    1   0       0   0     0    0    0   \n",
      "...      ...       ...      ...  ...  ...  ..     ...  ..   ...  ...  ...   \n",
      "28987      0         0        0  ...    0   0       0   0     0    0    0   \n",
      "28988      0         0        0  ...    0   0       0   0     0    0    0   \n",
      "28989      0         0        0  ...    0   0       0   0     0    0    0   \n",
      "28990      0         0        0  ...    0   0       0   0     0    0    0   \n",
      "28991      0         0        0  ...    0   0       0   0     0    0    0   \n",
      "\n",
      "       XXXL  full-price  sale-price  \n",
      "0         0    5.872118    5.872118  \n",
      "1         0    4.828314    4.828314  \n",
      "2         0    4.828314    4.828314  \n",
      "3         0    6.040255    6.040255  \n",
      "4         0    6.453625    6.453625  \n",
      "...     ...         ...         ...  \n",
      "28987     0    5.579730    4.828314  \n",
      "28988     0    6.445720    5.998937  \n",
      "28989     0    6.300786    5.886104  \n",
      "28990     0    7.170120    6.590301  \n",
      "28991     0    7.309881    6.729824  \n",
      "\n",
      "[28992 rows x 1069 columns]\n"
     ]
    }
   ],
   "source": [
    "ssense_rec_df = pd.concat([data['sku'],\n",
    "              category_matrix,brand_matrix,topic_matrix,\n",
    "              color_matrix, origin_matrix,\n",
    "              composition_matrix, size_matrix,\n",
    "              data['full-price'], data['sale-price']], \n",
    "              axis=1, ignore_index=False)\n",
    "\n",
    "print(ssense_rec_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From 9 orignal features that we deemed useful for the recommandation system, we have engineered and created 1069 new features that will be used to train the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_out = open(\"ssense_rec_df.pickle\",\"wb\")\n",
    "pickle.dump(ssense_rec_df,pickle_out)\n",
    "pickle_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
